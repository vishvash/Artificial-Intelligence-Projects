# -*- coding: utf-8 -*-
"""AutoML (TPOT).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MiKADs0EsNf98_4SpczHAPDgMULN4g6U
"""

!pip install TPOT

from tpot import TPOTClassifier
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split

digits = load_digits()
X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, train_size = 0.75, test_size = 0.25)
X_train.shape, X_test.shape, y_train.shape

"""***Hyperparameters for TPOT***"""

class tpot.TPOTClassifier(generations=100, population_size=100, offspring_size=None, mutation_rate=0.9, crossover_rate+0.1, scoring='accuracy', cv=5, subsample=1.0, n_jobs=1, max_time_mins = None, max_eval_time_mins=5, 
                          random_state=None, config_dict=None, template=None, warm_start=False, memory=None, use_dask=False, periodic_checkpoint_folder=None, early_stop=None, verbosity=0, disable_update_check+False, log_file=None)

tpot = TPOTClassifier(verbosity=2, max_time_mins=1, population_size=40)
tpot.fit(X_train, y_train)
print(tpot.score(X_test, y_test))

from google.colab import drive
drive.mount('/content/drive')

tpot = TPOTClassifier(verbosity=2, max_time_mins=5, population_size=40)
tpot.fit(X_train, y_train)
print(tpot.score(X_test, y_test))

tpot = TPOTClassifier(verbosity=2, max_time_mins=15, population_size=40)
tpot.fit(X_train, y_train)
print(tpot.score(X_test, y_test))

tpot.export('tpot_digits_pipeline.py')

import numpy as np
import pandas as pd
import numpy as np
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.feature_selection import RFE
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.model_selection import train_test_split
from sklearn.pipeline import make_pipeline
from sklearn.datasets import load_digits
from sklearn.externals import joblib
from tpot.builtins import StackingEstimator

exported_pipeline = make_pipeline(
    StackingEstimator(estimator=GaussianNB()),
    RFE(estimator=ExtraTreesClassifier(criterion="entropy", max_features=0.55, n_estimators=100), step=0.8500000000000001),
    KNeighborsClassifier(n_neighbors=7, p=2, weights="uniform")
)

best_model = exported_pipeline._final_estimator

print("best model:\n", best_model)

import matplotlib.pyplot as plt
arr = np.zeros(64).reshape(1,64)
arr[0] = digits.images[11].reshape(1,64)
fig = plt.figure()
plt.imshow(digits.images[11], cmap = plt.cm.gray_r)
txt = "this is %d"%digits.target[10]
fig.text(0.1, 0.1, txt)

import joblib

digits = load_digits()
training_features, testing_features, training_target, testing_target = train_test_split(digits.data, digits.target, train_size=0.8, test_size = 0.2)
exported_pipeline.fit(training_features, training_target)
results = exported_pipeline.predict(arr)
print("the number is predicted to be " + str(results))
joblib.dump(exported_pipeline, 'digits_model.pkl')